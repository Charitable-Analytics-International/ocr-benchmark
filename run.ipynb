{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Tools Benchmark\n",
    "\n",
    "    Author: Jean-Romain Roy \n",
    "    Date: 23/09/2020\n",
    "\n",
    "This notebook contains scripts, test data and instructions explaining how to benchmark different OCR tools including CAI Meza, Google Vision, Amazon Textract and Tesseract.\n",
    "\n",
    "The test data is composed of actual pictures of logbooks from our pilots in the Republic of Congo. Out of the valid pictures (relatively clear handwriting, logbook borders are visible, page is well lit) a few were selected randomly.\n",
    "\n",
    "Images take two forms. In *test_data/full_images/*, images are in their raw format. In *test_data/cell_images/*, we already took care of cutting the individual cells from the source images. The tedious task of decoding the handwritten characters in the images has already been done and can be found in the same directories.\n",
    "\n",
    "The *test_data/full_images/* directory also has a json file containing the shape of each potential template as Meza is configured to match incoming images with preloaded templates. As an aside, preloading templates is a feature that allows Meza to organize images and reference each extracted cell. It also allows it to automatically rotate the image if it's not upright.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to test data\n",
    "BUBBLES_IMG_PATH = 'test_data/cell_images/bubbles/images/'\n",
    "BUBBLES_VALUES = 'test_data/cell_images/bubbles/values.txt'\n",
    "\n",
    "EASTERN_ARABIC_NUMERALS_IMG_PATH = 'test_data/cell_images/eastern_numerals/images/'\n",
    "EASTERN_ARABIC_NUMERALS_VALUES = 'test_data/cell_images/eastern_numerals/values.txt'\n",
    "\n",
    "WESTERN_ARABIC_NUMERALS_IMG_PATH = 'test_data/cell_images/western_numerals/images/'\n",
    "WESTERN_ARABIC_NUMERALS_VALUES = 'test_data/cell_images/western_numerals/values.txt'\n",
    "\n",
    "FULL_IMG_PATH = 'test_data/full_images/images/'\n",
    "FULL_IMG_VALUES = 'test_data/full_images/values.json'\n",
    "FULL_IMG_TEMPLATES = 'test_data/full_images/templates.json'\n",
    "\n",
    "# Paths to results\n",
    "RESULTS_BUBBLES_DIR = 'results/cell_images/bubbles/'\n",
    "RESULTS_EASTERN_ARABIC_NUMERALS_DIR = 'results/cell_images/eastern_numerals/'\n",
    "RESULTS_WESTERN_ARABIC_NUMERALS_DIR = 'results/cell_images/western_numerals/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bubbles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the path & values\n",
    "bubbles_df = pd.read_csv(BUBBLES_VALUES, index_col=False, delimiter=\";\", dtype={'filename': 'str', 'value': 'str'})\n",
    "\n",
    "# Create the filename column\n",
    "bubbles_df['filename'] = BUBBLES_IMG_PATH + bubbles_df['filename'].astype(str)\n",
    "\n",
    "# Replace , with .\n",
    "bubbles_df['value'].replace({',': '.'}, inplace=True, regex=True)\n",
    "\n",
    "# replace rows with NaN values with ''\n",
    "bubbles_df['value'] = bubbles_df['value'].fillna('')\n",
    "\n",
    "# print stats\n",
    "print(f\"Length of Validation Set = {len(bubbles_df.index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eastern Arabic Numerals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the path & values\n",
    "eastern_numerals_df = pd.read_csv(EASTERN_ARABIC_NUMERALS_VALUES, index_col=False, delimiter=\";\", dtype={'filename': 'str', 'value': 'str'})\n",
    "\n",
    "# Create the filename column\n",
    "eastern_numerals_df['filename'] = EASTERN_ARABIC_NUMERALS_IMG_PATH + eastern_numerals_df['filename'].astype(str)\n",
    "\n",
    "# Replace , with .\n",
    "eastern_numerals_df['value'].replace({',': '.'}, inplace=True, regex=True)\n",
    "\n",
    "# replace rows with NaN values with ''\n",
    "eastern_numerals_df['value'] = eastern_numerals_df['value'].fillna('')\n",
    "\n",
    "# print stats\n",
    "print(f\"Length of Validation Set = {len(eastern_numerals_df.index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Western Arabic Numerals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the path & values\n",
    "western_numerals_df = pd.read_csv(WESTERN_ARABIC_NUMERALS_VALUES, index_col=False, delimiter=\";\", dtype={'filename': 'str', 'value': 'str'})\n",
    "\n",
    "# Create the filename column\n",
    "western_numerals_df['filename'] = WESTERN_ARABIC_NUMERALS_IMG_PATH + western_numerals_df['filename'].astype(str)\n",
    "\n",
    "# Replace , with .\n",
    "western_numerals_df['value'].replace({',': '.'}, inplace=True, regex=True)\n",
    "\n",
    "# replace rows with NaN values with ''\n",
    "western_numerals_df['value'] = western_numerals_df['value'].fillna('')\n",
    "\n",
    "# print stats\n",
    "print(f\"Length of Validation Set = {len(western_numerals_df.index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dataframe\n",
    "full_dataframe = []\n",
    "\n",
    "# load file\n",
    "with open(FULL_IMG_VALUES) as json_file:\n",
    "    full_dataframe = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAI Meza\n",
    "Meza is able to fit the templates on the image and then decode each cell. We compare its accuracy with the actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Images\n",
    "Images were submitted to Meza and once processed, we simply downloaded the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file\n",
    "with open(FULL_IMG_VALUES) as json_file:\n",
    "    meza_full_dataframe = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init accuracy dict\n",
    "accuracy_dict = {}\n",
    "\n",
    "# go through images\n",
    "for image in full_dataframe:\n",
    "    \n",
    "    # grab attributes\n",
    "    image_id = image['image_id']\n",
    "    actual_cells = image['cells']\n",
    "    \n",
    "    # grab the predicted values\n",
    "    pred_df = None\n",
    "    for image_df in meza_full_dataframe:\n",
    "        if(image_df['image_id'] == image_id):\n",
    "            pred_df = image_df\n",
    "            break\n",
    "    \n",
    "    # check if we found the actual values\n",
    "    if(pred_df is None):\n",
    "        raise Exception(f'Could not find results for image with id ({image_id})')\n",
    "    \n",
    "    # grab attributes\n",
    "    pred_cells = pred_df['cells']\n",
    "    \n",
    "    # build dicts\n",
    "    pred_dict = {}\n",
    "    for cell in pred_cells:\n",
    "        pred_dict[cell['rect_id']] = cell['value']\n",
    "        \n",
    "    actual_dict = {}\n",
    "    for cell in actual_cells:\n",
    "        actual_dict[cell['rect_id']] = cell['value']\n",
    "        \n",
    "    # compare\n",
    "    total = 0\n",
    "    nbr_match = 0\n",
    "    for rect_id in pred_dict:\n",
    "        \n",
    "        # grab predicted value\n",
    "        pred_val = pred_dict[rect_id]       \n",
    "        \n",
    "        # grab actual\n",
    "        actual_val = actual_dict[rect_id]\n",
    "        \n",
    "        if(actual_val == pred_val):\n",
    "            nbr_match += 1\n",
    "        total += 1\n",
    "        \n",
    "    # set accuracy\n",
    "    accuracy_dict[image_id] = nbr_match/float(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "print(\"### Meza Results ###\")\n",
    "for image_id in accuracy_dict:\n",
    "    accuracy = round(accuracy_dict[image_id]*10000.0)/100.0\n",
    "    print(f'Accuracy for {image_id}: {accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell images\n",
    "Here we fed the individual cell image one by one to Meza and noted the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Western Arabic Numerals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the predicted values\n",
    "results_df = pd.read_csv(f'{RESULTS_WESTERN_ARABIC_NUMERALS_DIR}meza/results.txt', index_col=False, delimiter=\";\", dtype={'filename': 'str', 'value': 'str'})\n",
    "\n",
    "# Replace , with .\n",
    "results_df['value'].replace({',': '.'}, inplace=True, regex=True)\n",
    "\n",
    "# replace rows with NaN values with ''\n",
    "results_df['value'] = results_df['value'].fillna('')\n",
    "\n",
    "# Compare\n",
    "total = 0\n",
    "nbr_match = 0\n",
    "for i, cell in western_numerals_df.iterrows():\n",
    "    \n",
    "    # grab attributes\n",
    "    filename = cell['filename'].split('/')[-1]\n",
    "    actual_val = cell['value']\n",
    "    \n",
    "    # grab the predicted values\n",
    "    cell_df = results_df.loc[results_df['filename'] == filename]\n",
    "    pred_val = cell_df['value'].tolist()[0]\n",
    "\n",
    "    # check if we found the actual values\n",
    "    if(pred_val is None):\n",
    "        raise Exception(f'Could not find results for cell with id ({filename})')\n",
    "    \n",
    "    if(actual_val == pred_val):\n",
    "        nbr_match += 1\n",
    "    total += 1\n",
    "\n",
    "# Display\n",
    "accuracy = round((nbr_match/float(total))*10000.0)/100.0\n",
    "print(f'Accuracy on cell images : {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eastern Arabic Numerals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the predicted values\n",
    "results_df = pd.read_csv(f'{RESULTS_EASTERN_ARABIC_NUMERALS_DIR}meza/results.txt', index_col=False, delimiter=\";\", dtype={'filename': 'str', 'value': 'str'})\n",
    "\n",
    "# Replace , with .\n",
    "results_df['value'].replace({',': '.'}, inplace=True, regex=True)\n",
    "\n",
    "# replace rows with NaN values with ''\n",
    "results_df['value'] = results_df['value'].fillna('')\n",
    "\n",
    "# Compare\n",
    "total = 0\n",
    "nbr_match = 0\n",
    "for i, cell in eastern_numerals_df.iterrows():\n",
    "    \n",
    "    # grab attributes\n",
    "    filename = cell['filename'].split('/')[-1]\n",
    "    actual_val = cell['value']\n",
    "    \n",
    "    # grab the predicted values\n",
    "    cell_df = results_df.loc[results_df['filename'] == filename]\n",
    "    pred_val = cell_df['value'].tolist()[0]\n",
    "\n",
    "    # check if we found the actual values\n",
    "    if(pred_val is None):\n",
    "        raise Exception(f'Could not find results for cell with id ({filename})')\n",
    "    \n",
    "    if(actual_val == pred_val):\n",
    "        nbr_match += 1\n",
    "    total += 1\n",
    "\n",
    "# Display\n",
    "accuracy = round((nbr_match/float(total))*10000.0)/100.0\n",
    "print(f'Accuracy on cell images : {accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bubbles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the predicted values\n",
    "results_df = pd.read_csv(f'{RESULTS_BUBBLES_DIR}meza/results.txt', index_col=False, delimiter=\";\", dtype={'filename': 'str', 'value': 'str'})\n",
    "\n",
    "# Replace , with .\n",
    "results_df['value'].replace({',': '.'}, inplace=True, regex=True)\n",
    "\n",
    "# replace rows with NaN values with ''\n",
    "results_df['value'] = results_df['value'].fillna('')\n",
    "\n",
    "# Compare\n",
    "total = 0\n",
    "nbr_match = 0\n",
    "for i, cell in bubbles_df.iterrows():\n",
    "    \n",
    "    # grab attributes\n",
    "    filename = cell['filename'].split('/')[-1]\n",
    "    actual_val = cell['value']\n",
    "    \n",
    "    # grab the predicted values\n",
    "    cell_df = results_df.loc[results_df['filename'] == filename]\n",
    "    pred_val = cell_df['value'].tolist()[0]\n",
    "\n",
    "    # check if we found the actual values\n",
    "    if(pred_val is None):\n",
    "        raise Exception(f'Could not find results for cell with id ({filename})')\n",
    "    \n",
    "    if(actual_val == pred_val):\n",
    "        nbr_match += 1\n",
    "    total += 1\n",
    "\n",
    "# Display\n",
    "accuracy = round((nbr_match/float(total))*10000.0)/100.0\n",
    "print(f'Accuracy on cell images : {accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesseract\n",
    "Tesseract doesn't feature true structured extraction. It can find text and return bounding boxes around it, but can't return the real table shape. Thus, we won't test it with the full images, only with the cell images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results\n",
    "if(os.path.exists(RESULTS_TESSERACT_CELLS)):\n",
    "    \n",
    "    # init dataframe\n",
    "    tesseract_cells_dataframe = []\n",
    "    \n",
    "    # Grab all the cell images with values\n",
    "    with open(RESULTS_TESSERACT_CELLS, 'r', encoding=\"utf-8\") as f:\n",
    "\n",
    "        # grab headers\n",
    "        headers = f.readline()\n",
    "        headers = [val.strip() for val in headers.split(';')]\n",
    "\n",
    "        # go through file\n",
    "        for row in f:\n",
    "\n",
    "            # split\n",
    "            values = [val.strip() for val in row.split(';')]\n",
    "\n",
    "            # create datum\n",
    "            datum = {}\n",
    "            for i, val in enumerate(headers):\n",
    "                datum[val] = values[i]\n",
    "\n",
    "            # push\n",
    "            tesseract_cells_dataframe.append(datum)\n",
    "            \n",
    "    # Compare\n",
    "    total = 0\n",
    "    nbr_match = 0\n",
    "    for cell in cells_dataframe:\n",
    "\n",
    "        # grab attributes\n",
    "        filename = cell['filename'].split('/')[-1]\n",
    "        actual_val = cell['value']\n",
    "\n",
    "        # grab the predicted values\n",
    "        pred_val = None\n",
    "        for cell_df in tesseract_cells_dataframe:\n",
    "            if(cell_df['filename'] == filename):\n",
    "                pred_val = cell_df['value']\n",
    "                break\n",
    "\n",
    "        # check if we found the actual values\n",
    "        if(pred_val is None):\n",
    "            raise Exception(f'Could not find results for cell with id ({filename})')\n",
    "\n",
    "        if(actual_val == pred_val):\n",
    "            nbr_match += 1\n",
    "        total += 1\n",
    "\n",
    "# Display\n",
    "accuracy = round((nbr_match/float(total))*10000.0)/100.0\n",
    "print(f'Accuracy on cell images : {accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To rerun tesseract on the cell images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     from PIL import Image\n",
    "# except ImportError:\n",
    "#     import Image\n",
    "# import pytesseract\n",
    "\n",
    "# # go through cells\n",
    "# total = 0\n",
    "# nbr_match = 0\n",
    "# for i, cell in enumerate(cells_dataframe):\n",
    "    \n",
    "#     # grab attributes\n",
    "#     filename = cell['filename']\n",
    "#     actual_val = cell['value']\n",
    "    \n",
    "#     # load image\n",
    "#     img = Image.open(filename)\n",
    "    \n",
    "#     # decode using tesseract\n",
    "#     pred_val = pytesseract.image_to_string(img)\n",
    "#     if(pred_val is None):\n",
    "#         pred_val = 'failed'\n",
    "    \n",
    "#     # format\n",
    "#     pred_val = str(pred_val).strip()\n",
    "#     pred_val = pred_val.replace('\\n', '')\n",
    "#     pred_val = pred_val.replace(',', '.')\n",
    "    \n",
    "#     # set\n",
    "#     cells_dataframe[i]['pred'] = pred_val\n",
    "    \n",
    "#     # Simple image to string\n",
    "#     if(actual_val == pred_val):\n",
    "#         nbr_match += 1\n",
    "#     total += 1\n",
    "    \n",
    "\n",
    "# # save results\n",
    "# with open(RESULTS_TESSERACT_CELLS, 'w+', newline='', encoding=\"utf-8\") as outfile:\n",
    "#     outfile.write(\"filename;value\\n\")\n",
    "    \n",
    "#     # go through cells\n",
    "#     for cell in cells_dataframe:\n",
    "#         filename = cell['filename'].split('/')[-1]\n",
    "#         pred_val = cell['pred']\n",
    "#         outfile.write(f\"{filename};{pred_val}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Vision\n",
    "Google also doesn't really feature table extraction, so we will only test the cell images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "#!pip3 install google-cloud-vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results\n",
    "if(os.path.exists(RESULTS_GOOGLE_CELLS)):\n",
    "    \n",
    "    # init dataframe\n",
    "    google_cells_dataframe = []\n",
    "    \n",
    "    # Grab all the cell images with values\n",
    "    with open(RESULTS_GOOGLE_CELLS, 'r', encoding=\"utf-8\") as f:\n",
    "\n",
    "        # grab headers\n",
    "        headers = f.readline()\n",
    "        headers = [val.strip() for val in headers.split(';')]\n",
    "\n",
    "        # go through file\n",
    "        for row in f:\n",
    "\n",
    "            # split\n",
    "            values = [val.strip() for val in row.split(';')]\n",
    "\n",
    "            # create datum\n",
    "            datum = {}\n",
    "            for i, val in enumerate(headers):\n",
    "                datum[val] = values[i]\n",
    "\n",
    "            # push\n",
    "            google_cells_dataframe.append(datum)\n",
    "            \n",
    "    # Compare\n",
    "    total = 0\n",
    "    nbr_match = 0\n",
    "    for cell in cells_dataframe:\n",
    "\n",
    "        # grab attributes\n",
    "        filename = cell['filename'].split('/')[-1]\n",
    "        actual_val = cell['value']\n",
    "\n",
    "        # grab the predicted values\n",
    "        pred_val = None\n",
    "        for cell_df in google_cells_dataframe:\n",
    "            if(cell_df['filename'] == filename):\n",
    "                pred_val = cell_df['value']\n",
    "                break\n",
    "\n",
    "        # check if we found the actual values\n",
    "        if(pred_val is None):\n",
    "            raise Exception(f'Could not find results for cell with id ({filename})')\n",
    "\n",
    "        if(actual_val == pred_val):\n",
    "            nbr_match += 1\n",
    "        total += 1\n",
    "\n",
    "# Display\n",
    "accuracy = round((nbr_match/float(total))*10000.0)/100.0\n",
    "print(f'Accuracy on cell images : {accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To rerun google on the cell images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # YOU NEED TO SETUP YOUR API KEY BEFORE RUNNING THIS\n",
    "# from google.cloud import vision\n",
    "\n",
    "# client = vision.ImageAnnotatorClient()\n",
    "\n",
    "# # Detects text in the file\n",
    "# def google_detect_text(path):\n",
    "\n",
    "#     with open(path, 'rb') as image_file:\n",
    "#         content = image_file.read()\n",
    "\n",
    "#     image = vision.Image(content=content)\n",
    "\n",
    "#     response = client.text_detection(image=image)\n",
    "#     texts = response.text_annotations\n",
    "\n",
    "#     for text in texts:\n",
    "#         return str('{}'.format(text.description)).strip()\n",
    "\n",
    "\n",
    "# # go through cells\n",
    "# total = 0\n",
    "# nbr_match = 0\n",
    "# for i, cell in western_numerals_df.iterrows():\n",
    "    \n",
    "#     # grab attributes\n",
    "#     filename = cell['filename']\n",
    "#     actual_val = cell['value']\n",
    "    \n",
    "#     # decode using google\n",
    "#     pred_val = google_detect_text(filename)\n",
    "#     if(pred_val is None):\n",
    "#         pred_val = 'failed'\n",
    "    \n",
    "#     # format\n",
    "#     pred_val = str(pred_val).strip()\n",
    "#     pred_val = pred_val.replace('\\n', '')\n",
    "#     pred_val = pred_val.replace(',', '.')\n",
    "    \n",
    "#     # set\n",
    "#     cells_dataframe[i]['pred'] = pred_val\n",
    "    \n",
    "#     # Simple image to string\n",
    "#     if(actual_val == pred_val):\n",
    "#         nbr_match += 1\n",
    "#     total += 1\n",
    "    \n",
    "\n",
    "# # save results\n",
    "# with open(RESULTS_GOOGLE_CELLS, 'w+', newline='', encoding=\"utf-8\") as outfile:\n",
    "#     outfile.write(\"filename;value\\n\")\n",
    "    \n",
    "#     # go through cells\n",
    "#     for cell in cells_dataframe:\n",
    "#         filename = cell['filename'].split('/')[-1]\n",
    "#         pred_val = cell['pred']\n",
    "#         outfile.write(f\"{filename};{pred_val}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Textract\n",
    "Amazon Textract is theoretically able to do structured extraction. Thus, we run both test for this benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the full images, I suggest that you upload the test images to amazon textract and use their user interface,\n",
    "    https://us-east-2.console.aws.amazon.com/textract/home?region=us-east-2#/demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are saved in the *results/aws/full_images/*. I have not taken the time to write code to analyse the results but I invite TECI to do so. Image captured with a high end camera in perfect lighting work relatively well, but the images from the field perform very poorly. Also, because we can't preload templates amazon textract messes up the table shape. On a final note, amazon textract doesn't handle checkboxes/bubbles or future data types that we are working on such as signatures, fingerprints, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell Images\n",
    "The performance are too low, I don't think I am hitting the right endpoint for these type of images. But the full image test is revealing of the performance on single cell images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results\n",
    "if(os.path.exists(RESULTS_AWS_CELLS)):\n",
    "    \n",
    "    # init dataframe\n",
    "    google_cells_dataframe = []\n",
    "    \n",
    "    # Grab all the cell images with values\n",
    "    with open(RESULTS_AWS_CELLS, 'r', encoding=\"utf-8\") as f:\n",
    "\n",
    "        # grab headers\n",
    "        headers = f.readline()\n",
    "        headers = [val.strip() for val in headers.split(';')]\n",
    "\n",
    "        # go through file\n",
    "        for row in f:\n",
    "\n",
    "            # split\n",
    "            values = [val.strip() for val in row.split(';')]\n",
    "\n",
    "            # create datum\n",
    "            datum = {}\n",
    "            for i, val in enumerate(headers):\n",
    "                datum[val] = values[i]\n",
    "\n",
    "            # push\n",
    "            google_cells_dataframe.append(datum)\n",
    "            \n",
    "    # Compare\n",
    "    total = 0\n",
    "    nbr_match = 0\n",
    "    for cell in cells_dataframe:\n",
    "\n",
    "        # grab attributes\n",
    "        filename = cell['filename'].split('/')[-1]\n",
    "        actual_val = cell['value']\n",
    "\n",
    "        # grab the predicted values\n",
    "        pred_val = None\n",
    "        for cell_df in google_cells_dataframe:\n",
    "            if(cell_df['filename'] == filename):\n",
    "                pred_val = cell_df['value']\n",
    "                break\n",
    "\n",
    "        # check if we found the actual values\n",
    "        if(pred_val is None):\n",
    "            raise Exception(f'Could not find results for cell with id ({filename})')\n",
    "\n",
    "        if(actual_val == pred_val):\n",
    "            nbr_match += 1\n",
    "        total += 1\n",
    "\n",
    "# Display\n",
    "accuracy = round((nbr_match/float(total))*10000.0)/100.0\n",
    "print(f'Accuracy on cell images : {accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To rerun aws on the cell images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "\n",
    "# # SET YOUR API KEY HERE\n",
    "# AWS_REGION_NAME=''\n",
    "# AWS_ACCESS_KEY_ID=''\n",
    "# AWS_SECRET_ACCESS_KEY=''\n",
    "# SESSION_TOKEN=''\n",
    "\n",
    "# # Amazon Textract client\n",
    "# textract = boto3.client(\n",
    "#     'textract', \n",
    "#     region_name=AWS_REGION_NAME,\n",
    "#     aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "#     aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "#     aws_session_token=SESSION_TOKEN\n",
    "# )\n",
    "\n",
    "# def aws_detect_text(path):\n",
    "\n",
    "#     # Read document content\n",
    "#     with open(path, 'rb') as document:\n",
    "#         imageBytes = bytearray(document.read())\n",
    "\n",
    "\n",
    "#     # Call Amazon Textract\n",
    "#     response = textract.detect_document_text(Document={'Bytes': imageBytes})\n",
    "\n",
    "#     textRes = []\n",
    "#     # Print detected text\n",
    "#     for item in response[\"Blocks\"]:\n",
    "#         if item[\"BlockType\"] == \"LINE\":\n",
    "#             textRes.append(item[\"Text\"])\n",
    "\n",
    "#     textRes = ','.join(textRes)\n",
    "#     if(len(textRes) == 0):\n",
    "#         textRes = 'failed'\n",
    "\n",
    "#     return textRes\n",
    "\n",
    "\n",
    "# # go through cells\n",
    "# total = 0\n",
    "# nbr_match = 0\n",
    "# for i, cell in enumerate(cells_dataframe):\n",
    "    \n",
    "#     # grab attributes\n",
    "#     filename = cell['filename']\n",
    "#     actual_val = cell['value']\n",
    "    \n",
    "#     # decode using google\n",
    "#     pred_val = aws_detect_text(filename)\n",
    "#     if(pred_val is None):\n",
    "#         pred_val = 'failed'\n",
    "    \n",
    "#     # format\n",
    "#     pred_val = str(pred_val).strip()\n",
    "#     pred_val = pred_val.replace('\\n', '')\n",
    "#     pred_val = pred_val.replace(',', '.')\n",
    "    \n",
    "#     # set\n",
    "#     cells_dataframe[i]['pred'] = pred_val\n",
    "    \n",
    "#     # Simple image to string\n",
    "#     if(actual_val == pred_val):\n",
    "#         nbr_match += 1\n",
    "#     total += 1\n",
    "    \n",
    "\n",
    "# # save results\n",
    "# with open(RESULTS_AWS_CELLS, 'w+', newline='', encoding=\"utf-8\") as outfile:\n",
    "#     outfile.write(\"filename;value\\n\")\n",
    "    \n",
    "#     # go through cells\n",
    "#     for cell in cells_dataframe:\n",
    "#         filename = cell['filename'].split('/')[-1]\n",
    "#         pred_val = cell['pred']\n",
    "#         outfile.write(f\"{filename};{pred_val}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
